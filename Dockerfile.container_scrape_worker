FROM python:3.9

WORKDIR /backend_copy


#install chrome for scrape process
RUN apt-get update && apt-get install -y wget unzip && \
    wget https://dl.google.com/linux/direct/google-chrome-stable_current_amd64.deb && \
    apt install -y ./google-chrome-stable_current_amd64.deb && \
    rm google-chrome-stable_current_amd64.deb && \
    apt-get clean


COPY backend_copy/requirements.txt /backend_copy/requirements.txt

RUN pip install --trusted-host pypi.python.org -r requirements.txt


COPY backend_copy/.env /backend_copy/.env
COPY backend_copy/.flaskenv /backend_copy/.flaskenv

COPY backend_copy/forms.py /backend_copy/forms.py
COPY backend_copy/app_main_runner.py /backend_copy/app_main_runner.py

COPY backend_copy/Data_Clean_Logic /backend_copy/Data_Clean_Logic
COPY backend_copy/Postgres_logic /backend_copy/Postgres_logic
COPY backend_copy/Web_Scrape_Logic /backend_copy/Web_Scrape_Logic


COPY backend_copy/LongTerm_prev_scrapes /backend_copy/LongTerm_prev_scrapes
COPY backend_copy/Scraped_data_output /backend_copy/Scraped_data_output
COPY backend_copy/Cleaned_data_output /backend_copy/Cleaned_data_output
COPY backend_copy/RabbitMQ_queues /backend_copy/RabbitMQ_queues  




ENV PYTHONPATH="${PYTHONPATH}:/backend_copy"


CMD ["python", "RabbitMQ_queues/scrape_worker.py"]